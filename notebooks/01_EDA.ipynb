{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f7665b2-6bb5-4c33-923b-cec3b8caf9e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.81\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       105\n",
      "           1       0.81      0.70      0.75        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "   PassengerId  Survived  Pclass  \\\n",
      "0            1         0       3   \n",
      "1            2         1       1   \n",
      "2            3         1       3   \n",
      "3            4         1       1   \n",
      "4            5         0       3   \n",
      "\n",
      "                                                Name     Sex   Age  SibSp  \\\n",
      "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                           Allen, Mr. William Henry    male  35.0      0   \n",
      "\n",
      "   Parch            Ticket     Fare Cabin Embarked  \n",
      "0      0         A/5 21171   7.2500   NaN        S  \n",
      "1      0          PC 17599  71.2833   C85        C  \n",
      "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3      0            113803  53.1000  C123        S  \n",
      "4      0            373450   8.0500   NaN        S  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "None\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n",
      "Shape of X: (891, 10)\n",
      "Shape of y: (891,)\n",
      "\n",
      "Models to train: dict_keys(['Gradient Boosting', 'KNN', 'Logistic Regression', 'Random Forest'])\n",
      "\n",
      "Training Gradient Boosting model...\n",
      "Accuracy: 0.82\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.88      0.85       105\n",
      "           1       0.81      0.74      0.77        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Training KNN model...\n",
      "Accuracy: 0.74\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.82      0.79       105\n",
      "           1       0.71      0.64      0.67        74\n",
      "\n",
      "    accuracy                           0.74       179\n",
      "   macro avg       0.74      0.73      0.73       179\n",
      "weighted avg       0.74      0.74      0.74       179\n",
      "\n",
      "\n",
      "Training Logistic Regression model...\n",
      "Accuracy: 0.79\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       105\n",
      "           1       0.77      0.72      0.74        74\n",
      "\n",
      "    accuracy                           0.79       179\n",
      "   macro avg       0.79      0.78      0.78       179\n",
      "weighted avg       0.79      0.79      0.79       179\n",
      "\n",
      "\n",
      "Training Random Forest model...\n",
      "Best Parameters: {'max_depth': 5, 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 300}\n",
      "Accuracy: 0.82\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.90      0.85       105\n",
      "           1       0.83      0.70      0.76        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.80      0.80       179\n",
      "weighted avg       0.82      0.82      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# ------------------ 1. Load Dataset ------------------ #\n",
    "def load_data(filepath):\n",
    "    \"\"\"Loads the Titanic dataset from the given file path.\"\"\"\n",
    "    df = pd.read_csv(filepath)\n",
    "    print(df.head())  # Display the first 5 rows\n",
    "    print(df.info())  # Dataset overview\n",
    "    print(df.describe())  # Statistical summary\n",
    "    return df\n",
    "\n",
    "# ------------------ 2. Data Preprocessing ------------------ #\n",
    "def preprocess_data(df):\n",
    "    \"\"\"Handles missing values, drops unnecessary columns, and encodes categorical data.\"\"\"\n",
    "    \n",
    "    # Fill missing values\n",
    "    df.fillna({'Embarked': df['Embarked'].mode()[0]}, inplace=True)\n",
    "    df.fillna({'Age': df['Age'].mean()}, inplace=True)\n",
    "\n",
    "    # Drop irrelevant columns\n",
    "    df.drop(['PassengerId', 'Name', 'Ticket', 'Cabin'], axis=1, inplace=True)\n",
    "\n",
    "    # Encode categorical variables\n",
    "    df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "    df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "    return df\n",
    "\n",
    "# ------------------ 3. Feature Engineering ------------------ #\n",
    "def featEng(df):\n",
    "    \"\"\"Creates new features to improve model performance.\"\"\"\n",
    "    df['FamilySize'] = df['SibSp'] + df['Parch'] + 1  # Total family members onboard\n",
    "    df['isAlone'] = (df['FamilySize'] == 1).astype(int)  # 1 if alone, else 0\n",
    "    df['FarePerPerson'] = df['Fare'] / df['FamilySize']  # Adjusted fare per person\n",
    "    return df\n",
    "\n",
    "# ------------------ 4. Split Data ------------------ #\n",
    "def split_data(df):\n",
    "    \"\"\"Splits data into training and test sets.\"\"\"\n",
    "    \n",
    "    # Define features and target variable\n",
    "    Feature_Selections = ['Sex', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked', 'FamilySize', 'isAlone', 'FarePerPerson']\n",
    "    X = df[Feature_Selections]\n",
    "    y = df['Survived']\n",
    "\n",
    "    # Print shapes\n",
    "    print(\"Shape of X:\", X.shape)  \n",
    "    print(\"Shape of y:\", y.shape)\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "# ------------------ 5. Model Training Functions ------------------ #\n",
    "\n",
    "def train_logistic_regression(X_train, y_train):\n",
    "    \"\"\"Trains a Logistic Regression model.\"\"\"\n",
    "    model = LogisticRegression(max_iter=500, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_knn(X_train, y_train):\n",
    "    \"\"\"Trains a K-Nearest Neighbors classifier.\"\"\"\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_gbc(X_train, y_train):\n",
    "    \"\"\"Trains a Gradient Boosting Classifier model.\"\"\"\n",
    "    model = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    return model\n",
    "\n",
    "def train_random_forest(X_train, y_train):\n",
    "    \"\"\"Trains a Random Forest Classifier model with GridSearchCV.\"\"\"\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [5, 10, None],\n",
    "        'min_samples_split': [2, 5, 10],\n",
    "        'min_samples_leaf': [1, 2, 4]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(RandomForestClassifier(random_state=42), param_grid, cv=5, n_jobs=-1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"Best Parameters:\", grid_search.best_params_)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    return best_model\n",
    "\n",
    "# ------------------ 6. Model Evaluation ------------------ #\n",
    "def evaluate_model(model, X_test, y_test):\n",
    "    \"\"\"Evaluates model performance using accuracy and classification report.\"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Print accuracy and classification report\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ------------------ Main Execution ------------------ #\n",
    "if __name__ == \"__main__\":\n",
    "    filepath = 'C:\\\\Users\\\\agrah\\\\OneDrive\\\\careers\\\\projects\\\\titanic survival rate predictions\\\\data\\\\train.csv'\n",
    "\n",
    "    # Load and process data\n",
    "    df = load_data(filepath)\n",
    "    df = preprocess_data(df)\n",
    "    df = featEng(df)  \n",
    "\n",
    "    # Split data\n",
    "    X_train, X_test, y_train, y_test = split_data(df)\n",
    "\n",
    "    # Define models\n",
    "    models = {\n",
    "        \"Gradient Boosting\": train_gbc,\n",
    "        \"KNN\": train_knn,\n",
    "        \"Logistic Regression\": train_logistic_regression,\n",
    "        \"Random Forest\": train_random_forest\n",
    "    }\n",
    "    \n",
    "    print(\"\\nModels to train:\", models.keys())\n",
    "\n",
    "    # Train and evaluate each model\n",
    "    for name, model_func in models.items():\n",
    "        print(f\"\\nTraining {name} model...\")\n",
    "        model = model_func(X_train, y_train)\n",
    "        evaluate_model(model, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2036b28c-e171-4b11-aab1-a9d77a288e23",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.81\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.89      0.85       105\n",
      "           1       0.81      0.70      0.75        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.79      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgb_model = XGBClassifier(n_estimators=200, max_depth=5, learning_rate=0.05, random_state=42)\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the new model\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "# Evaluate the XGBoost model\n",
    "accuracy_xgb = accuracy_score(y_test, y_pred_xgb)\n",
    "print(f\"XGBoost Accuracy: {accuracy_xgb:.2f}\")\n",
    "print(\"XGBoost Classification Report:\\n\", classification_report(y_test, y_pred_xgb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a63cadf4-efd8-4d44-a90b-c78348a5d106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agrah\\anaconda3\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
